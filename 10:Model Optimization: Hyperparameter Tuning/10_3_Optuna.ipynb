{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOr3kdhooUnfPMFhZk6LDF+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/soyebganja/DL-Practice-Projects/blob/main/10%3AModel%20Optimization%3A%20Hyperparameter%20Tuning/10_3_Optuna.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny-GDYlNf78Z",
        "outputId": "a0a05b1f-b9c7-42e4-e287-37de9bc05bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.15.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.40)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.13.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.0)\n",
            "Downloading optuna-4.3.0-py3-none-any.whl (386 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.15.2-py3-none-any.whl (231 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.15.2 colorlog-6.9.0 optuna-4.3.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "!pip install optuna # Install the missing optuna library\n",
        "import optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate sythetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "0C1NUs_agmCc"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxYPbuIGhVNQ",
        "outputId": "84064443-cbf6-4f0f-d610-0ec0fc1b212d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(800, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIxOuK-YhXQf",
        "outputId": "d34548c3-05c7-4990-8eae-012cdfa229ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.50363664, -1.51368248, -0.46907062,  1.90176571, -0.87064279,\n",
              "        1.82004715,  1.66291365,  1.29105223, -0.16713608, -1.04718436,\n",
              "        1.43003039,  0.20104766,  1.27577182, -1.13260729,  1.75008532,\n",
              "       -1.4089039 ,  0.03301588, -0.80340946, -1.31410638,  1.41209637])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CdSAgechgqn",
        "outputId": "6770265f-e4df-452d-fadf-49258c9fa886"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train, y_train = torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
        "X_test, y_test = torch.tensor(X_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)"
      ],
      "metadata": {
        "id": "1fwwwK_ahld6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)"
      ],
      "metadata": {
        "id": "yb5i0Q7CiQlL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "  hidden_dim = trial.suggest_int('hidden_dim', 10, 100)\n",
        "\n",
        "  model = SimpleNN(input_dim=20, hidden_dim=hidden_dim)\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  train_dataset = TensorDataset(X_train, y_train)\n",
        "\n",
        "\n",
        "  # Trainingloop\n",
        "  epochs = 20\n",
        "  batch_size = 32\n",
        "  train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "  test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=batch_size, shuffle=False)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    for batch_x, batch_y in train_loader:\n",
        "      optimizer.zero_grad()\n",
        "      output = model(batch_x)\n",
        "      loss = criterion(output, batch_y)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  # validation accuracy\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_x, batch_y in test_loader:\n",
        "      output = model(batch_x)\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += batch_y.size(0)\n",
        "      correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "  accuracy = correct / total\n",
        "\n",
        "  return accuracy\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaKkaN-0i0pn",
        "outputId": "9db7344a-2361-49e7-e1b2-6c1c411677e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-20 15:28:59,073] A new study created in memory with name: no-name-e576d436-63dd-4b59-80fb-8129a63e46cd\n",
            "<ipython-input-9-fd2fd2d7bf9c>:2: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
            "  learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
            "[I 2025-04-20 15:29:00,027] Trial 0 finished with value: 0.84 and parameters: {'learning_rate': 0.002039425471673405, 'hidden_dim': 82}. Best is trial 0 with value: 0.84.\n",
            "[I 2025-04-20 15:29:00,905] Trial 1 finished with value: 0.845 and parameters: {'learning_rate': 0.0018861769358919798, 'hidden_dim': 74}. Best is trial 1 with value: 0.845.\n",
            "[I 2025-04-20 15:29:01,651] Trial 2 finished with value: 0.86 and parameters: {'learning_rate': 0.0008719762440083374, 'hidden_dim': 87}. Best is trial 2 with value: 0.86.\n",
            "[I 2025-04-20 15:29:02,916] Trial 3 finished with value: 0.83 and parameters: {'learning_rate': 0.002157791008080844, 'hidden_dim': 97}. Best is trial 2 with value: 0.86.\n",
            "[I 2025-04-20 15:29:04,110] Trial 4 finished with value: 0.865 and parameters: {'learning_rate': 0.0021820282467894933, 'hidden_dim': 25}. Best is trial 4 with value: 0.865.\n",
            "[I 2025-04-20 15:29:04,977] Trial 5 finished with value: 0.815 and parameters: {'learning_rate': 0.00013506537448806073, 'hidden_dim': 67}. Best is trial 4 with value: 0.865.\n",
            "[I 2025-04-20 15:29:05,834] Trial 6 finished with value: 0.865 and parameters: {'learning_rate': 0.0006531706655150628, 'hidden_dim': 75}. Best is trial 4 with value: 0.865.\n",
            "[I 2025-04-20 15:29:07,116] Trial 7 finished with value: 0.605 and parameters: {'learning_rate': 2.5638847063738424e-05, 'hidden_dim': 75}. Best is trial 4 with value: 0.865.\n",
            "[I 2025-04-20 15:29:08,479] Trial 8 finished with value: 0.82 and parameters: {'learning_rate': 0.013534861966991808, 'hidden_dim': 72}. Best is trial 4 with value: 0.865.\n",
            "[I 2025-04-20 15:29:10,089] Trial 9 finished with value: 0.875 and parameters: {'learning_rate': 0.0010814105555317093, 'hidden_dim': 67}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:11,861] Trial 10 finished with value: 0.765 and parameters: {'learning_rate': 0.06646070319276501, 'hidden_dim': 42}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:13,409] Trial 11 finished with value: 0.84 and parameters: {'learning_rate': 0.013016947436244108, 'hidden_dim': 12}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:15,851] Trial 12 finished with value: 0.85 and parameters: {'learning_rate': 0.0001965151341414792, 'hidden_dim': 45}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:18,478] Trial 13 finished with value: 0.85 and parameters: {'learning_rate': 0.005454843709098926, 'hidden_dim': 24}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:19,793] Trial 14 finished with value: 0.73 and parameters: {'learning_rate': 6.795797998549952e-05, 'hidden_dim': 56}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:22,305] Trial 15 finished with value: 0.85 and parameters: {'learning_rate': 0.00040004647433310305, 'hidden_dim': 30}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:23,634] Trial 16 finished with value: 0.84 and parameters: {'learning_rate': 0.055335655407583076, 'hidden_dim': 57}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:25,699] Trial 17 finished with value: 0.825 and parameters: {'learning_rate': 0.006507205778690398, 'hidden_dim': 40}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:27,846] Trial 18 finished with value: 0.525 and parameters: {'learning_rate': 1.237549165110806e-05, 'hidden_dim': 11}. Best is trial 9 with value: 0.875.\n",
            "[I 2025-04-20 15:29:31,052] Trial 19 finished with value: 0.845 and parameters: {'learning_rate': 0.00039068764971462755, 'hidden_dim': 29}. Best is trial 9 with value: 0.875.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qltPy9jq0Qo3",
        "outputId": "6bae4804-f36d-47f6-ecf4-0948629d26f9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'learning_rate': 0.0010814105555317093, 'hidden_dim': 67}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aAfWzIo40ddW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}